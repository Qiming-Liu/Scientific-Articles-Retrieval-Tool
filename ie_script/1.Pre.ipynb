{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96605d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data folder\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89342260",
   "metadata": {},
   "outputs": [],
   "source": [
    "currect_path = os.getcwd()\n",
    "folder_path = '\\\\archive_2'\n",
    "path_data = currect_path+'\\\\data'\n",
    "path_fig = currect_path+'\\\\figure'\n",
    "path_model = currect_path+'\\\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5156ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(path_data+'\\\\metadata.csv', dtype={'pubmed_id': str, 'mag_id': str, 'doi': str, 'pmcid': str,\n",
    "                                                         'who_covidence_id': str, 'arxiv_id': str,\n",
    "                                                         'pmc_json_files': str}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4615ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.drop(['mag_id', 'arxiv_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json = glob.glob(path_data+'\\\\document_parses\\\\pdf_json\\\\*.json', recursive=True)\n",
    "pmc_json = glob.glob(path_data+'\\\\document_parses\\\\pmc_json\\\\*.json', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb175a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_json(input):\n",
    "    with open(input) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # ADD FULL ABSTRACT\n",
    "        abstract = []\n",
    "        for temp in data['abstract']:\n",
    "            abstract.append(temp['text'])\n",
    "        abstract = ' '.join(abstract)\n",
    "\n",
    "        # ADD BODY TEXT\n",
    "        body_text = []\n",
    "        for temp in data['body_text']:\n",
    "            body_text.append(temp['text'])\n",
    "        body_text = ' '.join(body_text)\n",
    "\n",
    "        # ADD LAST NAME & INSTITUTION & COUNTRY\n",
    "        last_name = []\n",
    "        institution = []\n",
    "        country = []\n",
    "        for temp in data['metadata']['authors']:\n",
    "            try:\n",
    "                last_name.append(temp['last'])\n",
    "                institution.append(temp['affiliation']['institution'])\n",
    "                country.append(temp['affiliation']['location']['country'])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        out = {'paper_id': data['paper_id'],\n",
    "                          'title': data['metadata']['title'],\n",
    "                          'authors': last_name,\n",
    "                          'institution': set(institution),\n",
    "                          'country': set(country),\n",
    "                          'abstract': abstract,\n",
    "                          'body_text': body_text}\n",
    "        \n",
    "        df = pd.DataFrame([out], columns=out.keys())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd8005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 256803/256803 [2:26:30<00:00, 29.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read pdf json\n",
    "df_pdf = pd.DataFrame(columns=['paper_id','title','authors','institution','country','abstract','body_text'])\n",
    "\n",
    "for i in tqdm(pdf_json):\n",
    "    try:\n",
    "        df_pdf = pd.concat([df_pdf, read_pdf_json(i)], axis =0, ignore_index=True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad26aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_pdf, open(path_data+'\\\\pdf_json.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e650158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pmc_json(input):\n",
    "    with open(input) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # ADD BODY TEXT\n",
    "        body_text = []\n",
    "        for temp in data['body_text']:\n",
    "            body_text.append(temp['text'])\n",
    "        body_text = ' '.join(body_text)\n",
    "\n",
    "        # ADD LAST NAME & INSTITUTION & COUNTRY\n",
    "        last_name = []\n",
    "        for temp in data['metadata']['authors']:\n",
    "            last_name.append(temp['last'])\n",
    "\n",
    "        out = {'paper_id': data['paper_id'],\n",
    "                          'title': data['metadata']['title'],\n",
    "                          'authors': last_name,\n",
    "                          'body_text': body_text}\n",
    "        \n",
    "        df = pd.DataFrame([out], columns=out.keys())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ce71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 197394/197394 [1:03:26<00:00, 51.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read pmc json\n",
    "df_pmc = pd.DataFrame(columns=['paper_id','title','authors','body_text'])\n",
    "for i in tqdm(pmc_json):\n",
    "    try:\n",
    "        df_pmc = pd.concat([df_pmc, read_pmc_json(i)], axis =0, ignore_index=True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_pmc, open(path_data+'\\\\pmc_json.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63db42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alan\\scoop\\apps\\python36\\current\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (1,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# LOAD META-DATA\n",
    "df_meta = pd.read_csv(path_data+'\\\\metadata.csv', dtype={'pubmed_id': str, 'mag_id': str, 'doi': str, 'pmcid': str,\n",
    "                                                         'who_covidence_id': str, 'arxiv_id': str, 'pmc_json_files': str})\n",
    "\n",
    "# DROP 2 COLUMNS THAT HAVE 98.7% AND 100% MISSING VALUES\n",
    "df_meta.drop(['mag_id','arxiv_id','url','pdf_json_files','pmc_json_files','license'], axis=1, inplace=True)\n",
    "\n",
    "# LOAD PDF_JSON AND PMC_JSON\n",
    "df_pdf = pickle.load(open(path_data+'\\\\pdf_json.sav', 'rb'))\n",
    "df_pmc = pickle.load(open(path_data+'\\\\pmc_json.sav', 'rb'))\n",
    "\n",
    "df = pd.merge(df_meta, df_pdf.drop(['title','authors','abstract'], axis=1), left_on='sha', right_on='paper_id', how='left')\n",
    "df.drop('paper_id', axis=1, inplace=True)\n",
    "df = pd.merge(df, df_pmc.drop(['title','authors'], axis=1), left_on='pmcid', right_on='paper_id', how='left')\n",
    "df.drop(['cord_uid','pubmed_id','s2_id','who_covidence_id','paper_id'], axis=1, inplace=True)\n",
    "\n",
    "# ONLY SELECT DATA WITH NOT-NULL BODY TEXT\n",
    "df = df[~df.body_text_x.isnull() | ~df.body_text_y.isnull()]\n",
    "\n",
    "# REMOVE NON-ENGLISH ARTICLE\n",
    "def language_detect(data):\n",
    "    languages = []\n",
    "    for i in tqdm(df.title):\n",
    "        try:\n",
    "            languages.append(detect(i))\n",
    "        except:\n",
    "            languages.append('unknown')\n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07243c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 251123/251123 [19:31<00:00, 214.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# ONLY SELECT ENGLISH ARTICLES\n",
    "df['languages'] = language_detect(df.title)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f859d697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 240348/240348 [19:09<00:00, 209.05it/s]\n"
     ]
    }
   ],
   "source": [
    "df['languages'] = language_detect(df.body_text_x)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb3ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 239777/239777 [19:21<00:00, 206.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df['languages'] = language_detect(df.body_text_y)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab94c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop('languages', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOWER CASE\n",
    "# for i in ['title','abstract','body_text_x','body_text_y']:\n",
    "#     df[i] = df[i].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4f2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE STOP WORDS\n",
    "# from nltk.corpus import stopwords\n",
    "# words = stopwords.words('english')\n",
    "# filtered_words = [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9e5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def sentence2list(lst):\n",
    "    return (lst[0].split())\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    list1 = sentence2list(list1)\n",
    "    list2 = sentence2list(list2)\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e92c4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 239414/239414 [04:17<00:00, 931.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    try:\n",
    "        df.loc[i, 'jaccard_similarity'] = jaccard_similarity(df.body_text_x[i], df.body_text_y[i])\n",
    "    except:\n",
    "        df.loc[i, 'jaccard_similarity']\n",
    "\n",
    "\n",
    "df['body_text'] = df.apply(lambda row: str(row['body_text_x'])+'; '+str(row['body_text_y']) if row['jaccard_similarity']<0.8 else row['body_text_y'], axis=1)\n",
    "df.drop(['body_text_x','body_text_y','jaccard_similarity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f318ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(path_data+'\\\\data.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255182fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open(path_data+'\\\\data.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f844845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:40<00:00, 33.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# CLEANING TITLE, ABSTRACT & BODY_TEXT\n",
    "c_var = ['title','abstract','body_text']\n",
    "for i in tqdm(c_var):\n",
    "    # Remove website url, [], doble space\n",
    "    df[i] = df[i].str.strip().str.replace(r'^((https?|ftp|smtp):\\/\\/)?(www.)?[a-z0-9]+\\.[a-z]+(\\/[a-zA-Z0-9#]+\\/?)*$','', regex=True).replace(\"[\\[].*?[\\)\\]]\", \"\", regex=True).replace(\"  \",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88046a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN\n",
    "df = df.dropna(axis=0, subset=['abstract','body_text']).reset_index(drop=True)\n",
    "pickle.dump(df, open(path_data+'\\\\cleaned_data.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1490d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "451px",
    "left": "1070px",
    "right": "20px",
    "top": "49px",
    "width": "538px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
