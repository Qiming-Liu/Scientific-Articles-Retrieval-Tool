{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96605d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b6a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5156ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "currect_path = os.getcwd()\n",
    "folder_path = '\\\\archive_2'\n",
    "path_data = currect_path+'\\\\data'\n",
    "path_fig = currect_path+'\\\\figure'\n",
    "path_model = currect_path+'\\\\model'\n",
    "df_meta = pd.read_csv(path_data+'\\\\metadata.csv', dtype={'pubmed_id': str, 'mag_id': str, 'doi': str, 'pmcid': str,\n",
    "                                                         'who_covidence_id': str, 'arxiv_id': str,\n",
    "                                                         'pmc_json_files': str}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4615ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.drop(['mag_id', 'arxiv_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json = glob.glob(path_data+'\\\\document_parses\\\\pdf_json\\\\*.json', recursive=True)\n",
    "pmc_json = glob.glob(path_data+'\\\\document_parses\\\\pmc_json\\\\*.json', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb175a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_json(input):\n",
    "    out = pd.DataFrame()\n",
    "    with open(input) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # ADD FULL ABSTRACT\n",
    "        abstract = []\n",
    "        for temp in data['abstract']:\n",
    "            abstract.append(temp['text'])\n",
    "        abstract = ' '.join(abstract)\n",
    "\n",
    "        # ADD BODY TEXT\n",
    "        body_text = []\n",
    "        for temp in data['body_text']:\n",
    "            body_text.append(temp['text'])\n",
    "        body_text = ' '.join(body_text)\n",
    "\n",
    "        # ADD LAST NAME & INSTITUTION & COUNTRY\n",
    "        last_name = []\n",
    "        institution = []\n",
    "        country = []\n",
    "        for temp in data['metadata']['authors']:\n",
    "            try:\n",
    "                last_name.append(temp['last'])\n",
    "                institution.append(temp['affiliation']['institution'])\n",
    "                country.append(temp['affiliation']['location']['country'])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        out = out.append({'paper_id': data['paper_id'],\n",
    "                          'title': data['metadata']['title'],\n",
    "                          'authors': last_name,\n",
    "                          'institution': set(institution),\n",
    "                          'country': set(country),\n",
    "                          'abstract': abstract,\n",
    "                          'body_text': body_text}, ignore_index=True)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd8005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 256803/256803 [2:26:49<00:00, 29.15it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pdf = pd.DataFrame(columns=['paper_id','title','authors','institution','country','abstract','body_text'])\n",
    "for i in tqdm(pdf_json):\n",
    "    try:\n",
    "        df_pdf = df_pdf.append(read_pdf_json(i), ignore_index=True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad26aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_pdf, open(path_data+'\\\\pdf_json.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e650158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pmc_json(input):\n",
    "    out = pd.DataFrame()\n",
    "    with open(input) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # ADD BODY TEXT\n",
    "        body_text = []\n",
    "        for temp in data['body_text']:\n",
    "            body_text.append(temp['text'])\n",
    "        body_text = ' '.join(body_text)\n",
    "\n",
    "        # ADD LAST NAME & INSTITUTION & COUNTRY\n",
    "        last_name = []\n",
    "        for temp in data['metadata']['authors']:\n",
    "            last_name.append(temp['last'])\n",
    "\n",
    "        out = out.append({'paper_id': data['paper_id'],\n",
    "                          'title': data['metadata']['title'],\n",
    "                          'authors': last_name,\n",
    "                          'body_text': body_text}, ignore_index=True)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1281ced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 197394/197394 [1:12:31<00:00, 45.36it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pmc = pd.DataFrame(columns=['paper_id','title','authors','body_text'])\n",
    "for i in tqdm(pmc_json):\n",
    "    try:\n",
    "        df_pmc = df_pmc.append(read_pmc_json(i), ignore_index=True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95feb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_pmc, open(path_data+'\\\\pmc_json.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63db42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pross\\scoop\\apps\\miniconda3\\current\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (1,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# LOAD META-DATA\n",
    "df_meta = pd.read_csv(path_data+'\\\\metadata.csv', dtype={'pubmed_id': str, 'mag_id': str, 'doi': str, 'pmcid': str,\n",
    "                                                         'who_covidence_id': str, 'arxiv_id': str, 'pmc_json_files': str})\n",
    "\n",
    "# DROP 2 COLUMNS THAT HAVE 98.7% AND 100% MISSING VALUES\n",
    "df_meta.drop(['mag_id','arxiv_id','url','pdf_json_files','pmc_json_files','license'], axis=1, inplace=True)\n",
    "\n",
    "# LOAD PDF_JSON AND PMC_JSON\n",
    "df_pdf = pickle.load(open(path_data+'\\\\pdf_json.sav', 'rb'))\n",
    "df_pmc = pickle.load(open(path_data+'\\\\pmc_json.sav', 'rb'))\n",
    "\n",
    "df = pd.merge(df_meta, df_pdf.drop(['title','authors','abstract'], axis=1), left_on='sha', right_on='paper_id', how='left')\n",
    "df.drop('paper_id', axis=1, inplace=True)\n",
    "df = pd.merge(df, df_pmc.drop(['title','authors'], axis=1), left_on='pmcid', right_on='paper_id', how='left')\n",
    "df.drop(['cord_uid','pubmed_id','s2_id','who_covidence_id','paper_id'], axis=1, inplace=True)\n",
    "\n",
    "# ONLY SELECT DATA WITH NOT-NULL BODY TEXT\n",
    "df = df[~df.body_text_x.isnull() | ~df.body_text_y.isnull()]\n",
    "\n",
    "# REMOVE NON-ENGLISH ARTICLE\n",
    "def language_detect(data):\n",
    "    languages = []\n",
    "    for i in tqdm(df.title):\n",
    "        try:\n",
    "            languages.append(detect(i))\n",
    "        except:\n",
    "            languages.append('unknown')\n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07243c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 251103/251103 [19:49<00:00, 211.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# ONLY SELECT ENGLISH ARTICLES\n",
    "df['languages'] = language_detect(df.title)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f859d697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 240314/240314 [17:59<00:00, 222.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df['languages'] = language_detect(df.body_text_x)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb3ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 239730/239730 [17:55<00:00, 222.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df['languages'] = language_detect(df.body_text_y)\n",
    "df = df[df['languages']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab94c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9e5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('languages', axis=1, inplace=True)\n",
    "\n",
    "# LOWER CASE BODY_TEXT X & Y, REMOVE STOP WORDS\n",
    "for i in ['title','abstract','body_text_x','body_text_y']:\n",
    "    df[i] = df[i].str.strip().str.lower()\n",
    "\n",
    "def sentence2list(lst):\n",
    "    return (lst[0].split())\n",
    "\n",
    "punctuations = string.punctuation\n",
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e92c4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 239393/239393 [03:49<00:00, 1040.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    list1 = sentence2list(list1)\n",
    "    list2 = sentence2list(list2)\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "# index=4\n",
    "# jaccard_similarity(df.body_text_x[index], df.body_text_y[index])\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    try:\n",
    "        df.loc[i, 'jaccard_similarity'] = jaccard_similarity(df.body_text_x[i], df.body_text_y[i])\n",
    "    except:\n",
    "        df.loc[i, 'jaccard_similarity']\n",
    "\n",
    "\n",
    "df['body_text'] = df.apply(lambda row: str(row['body_text_x'])+'; '+str(row['body_text_y']) if row['jaccard_similarity']<0.8 else row['body_text_y'], axis=1)\n",
    "df.drop(['body_text_x','body_text_y','jaccard_similarity'], axis=1, inplace=True)\n",
    "\n",
    "pickle.dump(df, open(path_data+'\\\\cleaned_data.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f844845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [06:47<00:00, 135.82s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pickle.load(open(path_data+'\\\\cleaned_data.sav', 'rb'))\n",
    "\n",
    "# CLEANING TITLE, ABSTRACT & BODY_TEXT\n",
    "c_var = ['title','abstract','body_text']\n",
    "for i in tqdm(c_var):\n",
    "    df[i] = df[i].str.strip().str.lower().replace(r'https?:\\S+\\sdoi','', regex=True).replace(\"[\\[].*?[\\)\\]]\", \"\", regex=True).replace(\"  \",\"\", regex=True)\n",
    "\n",
    "pickle.dump(df, open(path_data+'\\\\cleaned_data.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88046a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(path_data+'\\\\cleaned_data.sav', 'rb'))\n",
    "df = df.dropna(axis=0, subset=['abstract','body_text']).reset_index(drop=True)\n",
    "\n",
    "pickle.dump(df, open(path_data+'\\\\cleaned_data_no_null.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2761d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "451px",
    "left": "1070px",
    "right": "20px",
    "top": "49px",
    "width": "538px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
